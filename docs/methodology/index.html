<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ONTO — Methodology: The Science Behind ROOT</title>
<meta name="description" content="ONTO methodology: Shannon entropy, Kolmogorov complexity, eigenvalue decomposition. ECE, U-Recall, EM1-EM5 taxonomy. GOLD v4.5 reference standard. The science behind continuous epistemic grounding.">
<meta name="keywords" content="ONTO methodology, epistemic calibration, ECE, U-Recall, Shannon entropy, Kolmogorov complexity, eigenvalue decomposition, EM1-EM5 taxonomy, GOLD reference standard, AI epistemic risk, epistemic grounding">
<meta name="author" content="ONTO Standards Council">
<meta property="og:title" content="ONTO — Methodology: The Science Behind ROOT">
<meta property="og:description" content="How ONTO grounds AI systems in mathematical reality. ECE, U-Recall, EM1-EM5 taxonomy, GOLD v4.5, proof chain architecture.">
<meta property="og:url" content="https://ontostandard.org/methodology/">
<meta property="og:type" content="article">
<link rel="canonical" href="https://ontostandard.org/methodology/">

<!-- llms.txt reference -->
<link rel="alternate" type="text/plain" href="/llms.txt" title="LLM Context">

<link rel="icon" type="image/svg+xml" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 36 36'%3E%3Ccircle cx='18' cy='18' r='17' fill='white'/%3E%3Cpath d='M16 10L20 10L20 26L16 26L16 14L13 14L13 10L16 10Z' fill='%230a0a0a'/%3E%3C/svg%3E">

<!-- KaTeX for formulas -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css">
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.js"></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/contrib/auto-render.min.js" onload="renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}]})"></script>

<style>
:root {
    --bg: #0a0a0a;
    --bg-secondary: #121212;
    --bg-card: #1a1a1a;
    --bg-elevated: #242424;
    --border: #333333;
    --text: #fafafa;
    --text-secondary: #a0a0a0;
    --text-muted: #606060;
    --safe: #15803d;
    --safe-subtle: rgba(21, 128, 61, 0.15);
    --danger: #dc2626;
    --danger-subtle: rgba(220, 38, 38, 0.15);
    --warning: #d97706;
    --warning-subtle: rgba(217, 119, 6, 0.15);
    --mono: 'SF Mono', 'Fira Code', 'Cascadia Code', monospace;
    --sans: 'SF Pro Display', -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
}

* { margin: 0; padding: 0; box-sizing: border-box; }

body {
    font-family: var(--sans);
    background: var(--bg);
    color: var(--text);
    line-height: 1.7;
    -webkit-font-smoothing: antialiased;
}

/* === HEADER === */
.meth-header {
    position: fixed; top: 0; left: 0; right: 0; z-index: 100;
    background: rgba(10,10,10,0.92); backdrop-filter: blur(20px);
    border-bottom: 1px solid var(--border);
    padding: 0 40px; height: 56px;
    display: flex; align-items: center; justify-content: space-between;
}
.meth-header .logo {
    display: flex; align-items: center; gap: 10px;
    font-size: 18px; font-weight: 700; color: white;
    text-decoration: none;
}
.meth-header .logo svg { width: 28px; height: 28px; }
.meth-header nav { display: flex; gap: 24px; }
.meth-header nav a {
    color: var(--text-secondary); text-decoration: none; font-size: 13px;
    font-weight: 500; transition: color 0.2s;
}
.meth-header nav a:hover { color: white; }
.meth-header nav a.active { color: var(--safe); }

/* === MAIN === */
.meth-main {
    max-width: 820px; margin: 0 auto;
    padding: 96px 24px 120px;
}

/* === HERO === */
.meth-hero { margin-bottom: 64px; }
.meth-hero .label {
    font-family: var(--mono); font-size: 11px; text-transform: uppercase;
    letter-spacing: 2px; color: var(--text-muted); margin-bottom: 16px;
}
.meth-hero h1 {
    font-size: 36px; font-weight: 700; line-height: 1.2;
    color: white; margin-bottom: 16px;
}
.meth-hero .subtitle {
    font-size: 17px; color: var(--text-secondary); line-height: 1.6;
    max-width: 640px;
}

/* === SECTIONS === */
.meth-section { margin-bottom: 64px; }
.meth-section h2 {
    font-size: 22px; font-weight: 700; color: white;
    margin-bottom: 8px; padding-top: 24px;
    border-top: 1px solid var(--border);
}
.meth-section .section-num {
    font-family: var(--mono); font-size: 11px; color: var(--text-muted);
    margin-bottom: 4px; letter-spacing: 1px;
}
.meth-section p {
    margin-bottom: 16px; color: var(--text-secondary); font-size: 15px;
}

/* === FORMULAS === */
.formula-block {
    background: var(--bg-card); border: 1px solid var(--border);
    border-radius: 4px; padding: 28px 24px; margin: 24px 0;
    overflow-x: auto;
}
.formula-block .formula-label {
    font-family: var(--mono); font-size: 10px; text-transform: uppercase;
    letter-spacing: 2px; color: var(--text-muted); margin-bottom: 16px;
}
.formula-block .katex { font-size: 1.1em; }
.formula-block .formula-desc {
    font-size: 13px; color: var(--text-secondary); margin-top: 16px;
    line-height: 1.7;
}

/* === TABLES === */
.meth-table {
    width: 100%; border-collapse: collapse; margin: 24px 0;
    font-size: 14px;
}
.meth-table th {
    text-align: left; padding: 10px 12px;
    font-family: var(--mono); font-size: 10px; text-transform: uppercase;
    letter-spacing: 1.5px; color: var(--text-muted);
    border-bottom: 1px solid var(--border);
}
.meth-table td {
    padding: 10px 12px; border-bottom: 1px solid rgba(51,51,51,0.5);
    color: var(--text-secondary);
}
.meth-table tr:hover td { background: var(--bg-card); }
.meth-table .mono { font-family: var(--mono); font-size: 13px; }
.meth-table .accent { color: var(--safe); font-weight: 600; }
.meth-table .danger { color: var(--danger); }
.meth-table .dim { color: var(--text-secondary); }

/* === CODE === */
.code-block {
    background: var(--bg-card); border: 1px solid var(--border);
    border-radius: 4px; padding: 20px; margin: 20px 0;
    font-family: var(--mono); font-size: 13px; line-height: 1.6;
    overflow-x: auto; color: var(--text-secondary);
}
.code-block .keyword { color: var(--safe); }
.code-block .string { color: var(--warning); }
.code-block .comment { color: var(--text-muted); }

/* === DIAGRAM === */
.arch-diagram {
    background: var(--bg-card); border: 1px solid var(--border);
    border-radius: 4px; padding: 28px; margin: 24px 0;
    font-family: var(--mono); font-size: 12px;
    line-height: 1.8; white-space: pre; overflow-x: auto;
    color: var(--text-muted);
}
.arch-diagram .layer-name { color: var(--text); font-weight: 600; }
.arch-diagram .component { color: var(--text-secondary); }

/* === RESULTS === */
.result-card {
    background: var(--bg-card); border: 1px solid var(--border);
    border-radius: 4px; padding: 24px; margin: 12px 0;
    display: flex; align-items: center; gap: 20px;
}
.result-card .metric {
    font-family: var(--mono); font-size: 28px; font-weight: 600;
    color: var(--safe); min-width: 90px;
}
.result-card .metric.danger { color: var(--danger); }
.result-card .label { font-size: 14px; color: var(--text-secondary); }
.result-card .desc { font-size: 13px; color: var(--text-muted); margin-top: 4px; }

/* === PROOF CHAIN === */
.proof-visual {
    background: var(--bg-card); border: 1px solid var(--border);
    border-radius: 4px; padding: 24px; margin: 24px 0;
    font-family: var(--mono); font-size: 12px;
}
.proof-step {
    display: flex; align-items: center; gap: 12px;
    padding: 8px 0; color: var(--text-secondary);
}
.proof-step .step-num {
    width: 22px; height: 22px; border-radius: 50%;
    background: rgba(21, 128, 61, 0.08); color: var(--safe);
    display: flex; align-items: center; justify-content: center;
    font-size: 10px; font-weight: 600; flex-shrink: 0;
    border: 1px solid rgba(21, 128, 61, 0.2);
}
.proof-step .arrow { color: var(--text-muted); }
.proof-step code { color: white; }

/* === SIDEBAR TOC === */
.toc {
    position: fixed; right: 24px; top: 80px;
    width: 180px; font-size: 12px;
}
.toc a {
    display: block; padding: 4px 0; color: var(--text-muted);
    text-decoration: none; transition: color 0.2s;
    border-left: 2px solid transparent; padding-left: 12px;
}
.toc a:hover, .toc a.active {
    color: var(--safe); border-left-color: var(--safe);
}

/* === FOOTER === */
.meth-footer {
    text-align: center; padding: 40px 24px;
    border-top: 1px solid var(--border);
    font-size: 13px; color: var(--text-muted);
}
.meth-footer a { color: var(--text-secondary); text-decoration: none; }
.meth-footer a:hover { color: var(--text); }

/* === NOTE BLOCKS === */
.note-block {
    background: var(--bg-card); border-left: 2px solid var(--border);
    padding: 16px 20px; margin: 24px 0; border-radius: 0 4px 4px 0;
    font-size: 14px; color: var(--text-secondary); line-height: 1.7;
}

/* === RESPONSIVE === */
@media (max-width: 1100px) { .toc { display: none; } }
@media (max-width: 600px) {
    .meth-hero h1 { font-size: 26px; }
    .meth-main { padding: 80px 16px 80px; }
    .meth-header { padding: 0 16px; }
    .meth-header nav { gap: 12px; }
    .meth-header nav a { font-size: 12px; }
    .result-card { flex-direction: column; align-items: flex-start; }
    .result-card .metric { font-size: 24px; }
}
</style>
</head>
<body>

<!-- HEADER -->
<header class="meth-header">
    <a href="/" class="logo">
        <svg width="28" height="28" viewBox="0 0 36 36" fill="none" xmlns="http://www.w3.org/2000/svg">
            <circle cx="18" cy="18" r="17" fill="white"/>
            <path d="M16 10L20 10L20 26L16 26L16 14L13 14L13 10L16 10Z" fill="#0a0a0a"/>
        </svg>
        <span>ONTO</span>
    </a>
    <nav>
        <a href="/docs/">Docs</a>
        <a href="/methodology/" class="active">Methodology</a>
        <a href="/audits/">Audits</a>
        <a href="/check/">Check</a>
        <a href="/app/">Portal</a>
    </nav>
</header>

<!-- TOC -->
<nav class="toc" id="toc">
    <a href="#foundations">Foundations</a>
    <a href="#dual-layer">Dual-Layer Scoring</a>
    <a href="#taxonomy">EM1–EM5 Taxonomy</a>
    <a href="#metrics">Metrics</a>
    <a href="#gold">GOLD v4.5</a>
    <a href="#proof">Proof Chain</a>
    <a href="#results">Results</a>
    <a href="#compliance">Compliance</a>
</nav>

<!-- MAIN -->
<main class="meth-main">

<!-- HERO -->
<div class="meth-hero">
    <div class="label">Methodology</div>
    <h1>The Science Behind ROOT</h1>
    <p class="subtitle">ONTO provides continuous epistemic grounding for AI systems. This document describes the mathematical foundations, scoring architecture, and verification mechanisms that make it work.</p>
</div>

<!-- §1 FOUNDATIONS -->
<section class="meth-section" id="foundations">
    <div class="section-num">§1</div>
    <h2>Mathematical Foundations</h2>

    <p>AI systems produce outputs without intrinsic knowledge of their own epistemic boundaries — what they know versus what they're guessing. ONTO addresses this through three mathematical pillars:</p>

    <div class="formula-block">
        <div class="formula-label">Shannon Entropy</div>
        $$H(X) = -\sum_{i=1}^{n} p(x_i) \log_2 p(x_i)$$
        <div class="formula-desc">Measures information uncertainty in model outputs. High entropy = distributed probability across possible answers = genuine uncertainty. Low entropy = concentrated probability = confidence (justified or not). ONTO uses Shannon entropy to detect when a model's output distribution reveals latent uncertainty that contradicts surface-level confident language.</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Kolmogorov Complexity</div>
        $$K(x) = \min\{|p| : U(p) = x\}$$
        <div class="formula-desc">The length of the shortest program that produces output x. ONTO approximates Kolmogorov complexity to measure response compressibility. Overclaimed responses tend to exhibit low complexity (formulaic hedging) while genuinely informed responses show structured complexity reflecting real knowledge.</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Eigenvalue Decomposition</div>
        $$A\mathbf{v} = \lambda\mathbf{v}$$
        <div class="formula-desc">Applied to the epistemic covariance matrix of model outputs across evaluation dimensions. Dominant eigenvalues reveal principal axes of epistemic variation — where a model's uncertainty is structured versus random. This separates calibrated uncertainty (model knows its limits) from uncalibrated confidence (model doesn't know what it doesn't know).</div>
    </div>

    <div class="note-block">These three foundations operate simultaneously. Shannon entropy quantifies uncertainty. Kolmogorov complexity measures structural integrity. Eigenvalue decomposition separates signal from noise. Together, they form GOLD — the reference standard against which AI outputs are grounded.</div>
</section>

<!-- §2 DUAL-LAYER -->
<section class="meth-section" id="dual-layer">
    <div class="section-num">§2</div>
    <h2>Dual-Layer Scoring Architecture</h2>

    <p>ONTO implements two independent analysis layers. Agreement between layers = verified grounding. Disagreement = epistemic risk detected.</p>

    <div class="arch-diagram"><span class="layer-name">LAYER 1: LINGUISTIC ANALYSIS</span>  ←  what the model <span class="component">SAYS</span>
│
│  Input: raw model output text
│  Engine: scoring_engine v3.0
│  Method: EM1-EM5 classification (92 epistemic markers)
│  Output: REP score [0,1]
│
├──────────────────────────────────────────
│
<span class="layer-name">LAYER 2: STATISTICAL ANALYSIS</span>  ←  how the model <span class="component">COMPUTES</span>
│
│  Input: probability distributions, token logits
│  Engine: onto_core (Rust)
│  Method: Shannon entropy + eigenvalue decomposition
│  Output: statistical confidence [0,1]
│
├──────────────────────────────────────────
│
<span class="layer-name">AGREEMENT CHECK</span>  →  <span class="component">DLA (Dual-Layer Agreement)</span>
│
│  If Layer 1 ≈ Layer 2  →  grounded (low epistemic risk)
│  If Layer 1 ≠ Layer 2  →  hallucination detected
│  Example: model says "certainly" but entropy is high
│           → DLA divergence → risk flagged</div>

    <p>The key insight: a model can <em>say</em> it's confident while its internal computations reveal uncertainty. Layer 1 catches linguistic overclaiming. Layer 2 catches statistical miscalibration. DLA catches disagreement between the two — the hallucination signature.</p>
</section>

<!-- §3 EM1-EM5 TAXONOMY -->
<section class="meth-section" id="taxonomy">
    <div class="section-num">§3</div>
    <h2>EM1–EM5 Epistemic Marker Taxonomy</h2>

    <p>Every AI output is classified across 92 epistemic markers organized into 5 levels:</p>

    <table class="meth-table">
        <thead>
            <tr><th>Level</th><th>Name</th><th>Description</th><th>Example</th></tr>
        </thead>
        <tbody>
            <tr>
                <td class="mono accent">EM1</td>
                <td>Full Epistemic Transparency</td>
                <td>Explicit acknowledgment of unknowns</td>
                <td class="dim">"This is not yet established..."</td>
            </tr>
            <tr>
                <td class="mono accent">EM2</td>
                <td>Calibrated Uncertainty</td>
                <td>Hedged assertions with appropriate qualifiers</td>
                <td class="dim">"Current evidence suggests..."</td>
            </tr>
            <tr>
                <td class="mono">EM3</td>
                <td>Neutral / Informational</td>
                <td>Factual statements without epistemic markers</td>
                <td class="dim">"The temperature is 20°C."</td>
            </tr>
            <tr>
                <td class="mono danger">EM4</td>
                <td>Confident Assertion</td>
                <td>Strong claims without hedging</td>
                <td class="dim">"This is definitely the case."</td>
            </tr>
            <tr>
                <td class="mono danger">EM5</td>
                <td>Overclaiming</td>
                <td>Unfounded confidence on open/contested topics</td>
                <td class="dim">"Consciousness is caused by..."</td>
            </tr>
        </tbody>
    </table>

    <p>EM1-EM2 on genuinely uncertain topics = epistemically grounded. EM4-EM5 on established facts = appropriate confidence. The problem occurs when EM4-EM5 appears on UNKNOWN or CONTESTED questions — this is the hallucination that ONTO detects and the ROOT connection prevents.</p>

    <div class="formula-block">
        <div class="formula-label">Response Epistemic Profile (REP)</div>
        $$\text{REP}(r) = \frac{\sum_{i=1}^{n} w_i \cdot \text{marker}_i(r)}{n}$$
        <div class="formula-desc">Weighted score across all detected epistemic markers in response r. Range [0,1] where 0 = maximum overclaiming (EM5 dominant) and 1 = full epistemic transparency (EM1 dominant). The weights w<sub>i</sub> are calibrated against GOLD v4.5 reference responses.</div>
    </div>
</section>

<!-- §4 METRICS -->
<section class="meth-section" id="metrics">
    <div class="section-num">§4</div>
    <h2>Core Metrics</h2>

    <div class="formula-block">
        <div class="formula-label">Expected Calibration Error (ECE)</div>
        $$\text{ECE} = \sum_{m=1}^{M} \frac{|B_m|}{n} \left| \text{acc}(B_m) - \text{conf}(B_m) \right|$$
        <div class="formula-desc">Average deviation between model's stated confidence and observed accuracy across M calibration bins. Range: 0.0 (perfectly calibrated) to 1.0 (maximally miscalibrated). A model reporting 90% confidence but achieving 70% accuracy has a per-bin gap of 0.20.</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Unknown Detection Rate (U-Recall)</div>
        $$\text{U-Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$
        <div class="formula-desc">Proportion of genuinely unknown/open questions correctly identified as uncertain. TP = correctly flagged unknowns. FN = unknowns missed (answered confidently). Range: 0% to 100%. The critical metric: can the system recognize what it doesn't know?</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Epistemic Calibration Error (EpCE)</div>
        $$\text{EpCE}(r) = |\text{REP}(r) - \text{REP}_{\text{GOLD}}(q)| \cdot \text{domain\_weight}(d)$$
        <div class="formula-desc">Distance between the model's epistemic profile and the GOLD reference profile for the same query, adjusted by domain weight. EpCE near 0 = the model's epistemic stance matches the scientifically correct stance. EpCE near 1 = severe miscalibration.</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Dual-Layer Agreement (DLA)</div>
        $$\text{DLA} = 1 - |\text{Layer1}(r) - \text{Layer2}(r)|$$
        <div class="formula-desc">Agreement between linguistic analysis and statistical analysis. DLA = 1.0 means what the model says matches how it computes. DLA near 0 indicates hallucination: confident language contradicted by uncertain computation, or vice versa.</div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Information Gap Ratio (IGR)</div>
        $$\text{IGR}(c) = \frac{|\text{missing\_deps}(c)| + |\text{unresolved}(c)|}{|\text{expected}(c)|}$$
        <div class="formula-desc">For a given claim c, the ratio of missing dependencies and unresolved contradictions to expected evidence. High IGR = the claim lacks sufficient grounding = requires epistemic disclosure.</div>
    </div>

    <p>These five metrics — ECE, U-Recall, REP, EpCE, DLA — plus IGR form the complete ONTO assessment. They are computed for every evaluation and signed with the current entropy signal.</p>
</section>

<!-- §5 GOLD -->
<section class="meth-section" id="gold">
    <div class="section-num">§5</div>
    <h2>GOLD v4.5 Reference Standard</h2>

    <p>GOLD (Grounded Ontological Language Dataset) is the calibration corpus against which all AI outputs are measured. It provides the scientific "ground truth" for epistemic classification.</p>

    <table class="meth-table">
        <thead>
            <tr><th>Property</th><th>Value</th></tr>
        </thead>
        <tbody>
            <tr><td>Version</td><td class="mono">4.5</td></tr>
            <tr><td>Calibration files</td><td class="mono">149</td></tr>
            <tr><td>Academic references</td><td class="mono">59 references, 8 primary sources</td></tr>
            <tr><td>Epistemic markers</td><td class="mono">92 patterns across EM1-EM5</td></tr>
            <tr><td>Domains</td><td class="mono">ED1-ED7 (medical, legal, financial, technical, scientific, general, creative)</td></tr>
            <tr><td>Validated samples</td><td class="mono">268 (ONTO-Bench)</td></tr>
            <tr><td>Label distribution</td><td class="mono">KNOWN: 126 · UNKNOWN: 110 · CONTRADICTION: 32</td></tr>
            <tr><td>Tier-1 sources</td><td class="dim">Clay Mathematics Institute, NSF/ERC Grand Challenges, Physics/Biology open problem surveys</td></tr>
            <tr><td>Tier-2 sources</td><td class="dim">NIST constants, established textbooks, Wikipedia open problem lists</td></tr>
            <tr><td>Validation rate</td><td class="mono accent">100%</td></tr>
        </tbody>
    </table>

    <p>GOLD encodes not just facts but their <em>epistemic status</em>: ESTABLISHED, CONTESTED, or UNKNOWN. This is the critical difference from RAG or knowledge graphs. A knowledge graph knows that water boils at 100°C. GOLD also knows that the nature of consciousness is UNKNOWN and that quantum interpretation is CONTESTED.</p>

    <div class="note-block">Domain-specific thresholds (TCI baselines) adjust scoring for each epistemic domain ED1-ED7. Medical domain (ED1) has the strictest thresholds — overclaiming in healthcare carries the highest risk. Creative domain (ED7) has the most permissive — confident assertions in creative writing are appropriate.</div>
</section>

<!-- §6 PROOF CHAIN -->
<section class="meth-section" id="proof">
    <div class="section-num">§6</div>
    <h2>Proof Chain Architecture</h2>

    <p>Every evaluation through ONTO ROOT produces a cryptographically signed proof — verifiable evidence that grounding occurred at a specific moment.</p>

    <div class="proof-visual">
        <div class="proof-step">
            <div class="step-num">1</div>
            <span>AI output received via ROOT connection</span>
        </div>
        <div class="proof-step">
            <div class="step-num">2</div>
            <span>Scoring engine v3.0 computes EM1-EM5 + REP + EpCE + DLA</span>
        </div>
        <div class="proof-step">
            <div class="step-num">3</div>
            <span>Current entropy signal fetched → <code>σ(t)</code></span>
        </div>
        <div class="proof-step">
            <div class="step-num">4</div>
            <span>Evaluation + entropy combined → <code>SHA-256 hash</code></span>
        </div>
        <div class="proof-step">
            <div class="step-num">5</div>
            <span>Hash signed with Ed25519 private key → <code>signature</code></span>
        </div>
        <div class="proof-step">
            <div class="step-num">6</div>
            <span>Output: 104-byte proof packet = <code>hash + signature + timestamp</code></span>
        </div>
    </div>

    <div class="formula-block">
        <div class="formula-label">Proof Packet Structure (104 bytes)</div>
        <div class="code-block" style="background:transparent;border:none;padding:0;margin:8px 0">
<span class="comment">// 32 bytes: SHA-256 hash of evaluation</span>
<span class="keyword">hash</span>     = SHA256(model_id + output + scores + entropy_signal)

<span class="comment">// 64 bytes: Ed25519 signature</span>
<span class="keyword">signature</span> = Ed25519.sign(hash, SIGNING_KEY)

<span class="comment">// 8 bytes: Unix timestamp (microseconds)</span>
<span class="keyword">timestamp</span> = time_μs()

<span class="comment">// Verification: anyone with public key can verify</span>
<span class="keyword">verified</span>  = Ed25519.verify(hash, signature, PUBLIC_KEY)</div>
        <div class="formula-desc">The proof is verifiable but unreproducible without the original entropy signal σ(t). This means results can be confirmed authentic but cannot be forged retroactively. Not blockchain — standard public-key cryptography.</div>
    </div>

    <p>While connected to ROOT, every evaluation is signed with the current entropy. Disconnection means no new entropy = no new proofs = certificate frozen. This is why ONTO is infrastructure, not a report.</p>
</section>

<!-- §7 RESULTS -->
<section class="meth-section" id="results">
    <div class="section-num">§7</div>
    <h2>Benchmark Results (ONTO-Bench)</h2>

    <p>ONTO-Bench evaluates the core question: can the system distinguish what is known from what is genuinely unknown? Results across 268 samples:</p>

    <div style="display:grid;grid-template-columns:1fr 1fr;gap:12px;margin:24px 0">
        <div class="result-card">
            <div class="metric">96%</div>
            <div>
                <div class="label">ONTO U-Recall</div>
                <div class="desc">Correctly identifies 96% of genuinely open questions</div>
            </div>
        </div>
        <div class="result-card">
            <div class="metric danger">&lt;10%</div>
            <div>
                <div class="label">Baseline U-Recall</div>
                <div class="desc">GPT-4, Claude 3, Llama 3 miss >90% of unknowns</div>
            </div>
        </div>
    </div>

    <table class="meth-table">
        <thead>
            <tr><th>Model</th><th>U-Precision</th><th>U-Recall</th><th>U-F1</th><th>ECE ↓</th><th>Accuracy</th></tr>
        </thead>
        <tbody>
            <tr>
                <td class="accent" style="font-weight:700">ONTO</td>
                <td class="mono">0.41</td>
                <td class="mono accent">0.96</td>
                <td class="mono accent">0.58</td>
                <td class="mono">0.30</td>
                <td class="mono">0.43</td>
            </tr>
            <tr>
                <td>Claude 3</td>
                <td class="mono">0.45</td>
                <td class="mono danger">0.09</td>
                <td class="mono">0.15</td>
                <td class="mono">0.31</td>
                <td class="mono">0.48</td>
            </tr>
            <tr>
                <td>Llama 3</td>
                <td class="mono">0.20</td>
                <td class="mono danger">0.01</td>
                <td class="mono">0.02</td>
                <td class="mono">0.33</td>
                <td class="mono">0.46</td>
            </tr>
            <tr>
                <td>GPT-4</td>
                <td class="mono">0.10</td>
                <td class="mono danger">0.01</td>
                <td class="mono">0.02</td>
                <td class="mono">0.34</td>
                <td class="mono">0.44</td>
            </tr>
        </tbody>
    </table>

    <p>The precision-recall tradeoff is intentional: ONTO prioritizes recall (catching unknowns) over precision. In high-stakes domains, false uncertainty is always preferable to false confidence. Missing a genuine unknown — answering confidently when you shouldn't — is the failure mode that costs lives and money.</p>

    <div class="note-block"><strong>Why do LLMs fail?</strong> LLMs are trained to produce fluent, helpful responses. The training objective rewards confident answers and does not penalize confident responses to unanswerable questions. Without explicit epistemic structure, they have no mechanism to recognize knowledge boundaries. ONTO provides that structure through the ROOT connection.</div>
</section>

<!-- §8 COMPLIANCE -->
<section class="meth-section" id="compliance">
    <div class="section-num">§8</div>
    <h2>Compliance Grades &amp; Regulatory Alignment</h2>

    <table class="meth-table">
        <thead>
            <tr><th>Grade</th><th>U-Recall</th><th>ECE</th><th>Certification</th></tr>
        </thead>
        <tbody>
            <tr><td class="accent" style="font-weight:700">A — EXEMPLARY</td><td class="mono">≥90%</td><td class="mono">≤0.05</td><td>Full</td></tr>
            <tr><td style="font-weight:600">B — STRONG</td><td class="mono">≥70%</td><td class="mono">≤0.10</td><td>Full</td></tr>
            <tr><td>C — ADEQUATE</td><td class="mono">≥50%</td><td class="mono">≤0.15</td><td>Conditional</td></tr>
            <tr><td>D — MARGINAL</td><td class="mono">≥30%</td><td class="mono">≤0.20</td><td>Not eligible</td></tr>
            <tr><td class="danger">F — CRITICAL</td><td class="mono">&lt;30%</td><td class="mono">&gt;0.20</td><td>Not eligible</td></tr>
        </tbody>
    </table>

    <p>ONTO compliance maps to existing regulatory frameworks:</p>

    <table class="meth-table">
        <thead>
            <tr><th>Framework</th><th>ONTO Mapping</th></tr>
        </thead>
        <tbody>
            <tr><td>EU AI Act (Annex III)</td><td>Continuous ROOT connection provides ongoing quantitative evidence for high-risk AI conformity assessment</td></tr>
            <tr><td>NIST AI RMF 1.0</td><td>ECE and U-Recall implement the MEASURE function (Map → Measure → Manage → Govern)</td></tr>
            <tr><td>ISO/IEC 42001</td><td>ONTO produces signed evaluation records, metric histories, and compliance determinations required for AI management system audits</td></tr>
        </tbody>
    </table>
</section>

<!-- FOOTER -->
<div style="margin-top:64px;padding-top:32px;border-top:1px solid var(--border)">
    <p style="font-size:14px;color:var(--text-secondary);margin-bottom:12px">This methodology is continuously refined. GOLD reference standard and scoring engine are versioned independently. Current: GOLD v4.5, scoring engine v3.0.</p>
    <p style="font-size:13px;color:var(--text-muted)">
        Research: <a href="https://github.com/nickarstrong/onto-research" style="color:var(--text-secondary);text-decoration:none">github.com/nickarstrong/onto-research</a> ·
        Documentation: <a href="/docs/" style="color:var(--text-secondary);text-decoration:none">ontostandard.org/docs</a> ·
        Contact: <a href="mailto:council@ontostandard.org" style="color:var(--text-secondary);text-decoration:none">council@ontostandard.org</a>
    </p>
</div>

</main>

<!-- Semantic content for AI crawlers -->
<div style="position:absolute;width:1px;height:1px;padding:0;margin:-1px;overflow:hidden;clip:rect(0,0,0,0);white-space:nowrap;border:0" role="complementary" aria-label="ONTO Methodology Technical Details">
<article>
<h1>ONTO Methodology — The Science Behind Continuous Epistemic Grounding</h1>
<p>ONTO provides continuous epistemic grounding for AI systems via ROOT connection to the GOLD v4.5 reference standard. The methodology combines three mathematical foundations: Shannon entropy (uncertainty quantification in model outputs), Kolmogorov complexity (structural integrity of responses), and eigenvalue decomposition (separating calibrated uncertainty from random noise). These operate through a dual-layer scoring architecture: Layer 1 (linguistic analysis via EM1-EM5 taxonomy, 92 epistemic markers) analyzes what the model says, Layer 2 (statistical analysis via onto_core Rust engine) analyzes how the model computes. Dual-Layer Agreement (DLA) detects hallucination when these layers disagree.</p>
<p>Five core metrics: ECE (Expected Calibration Error) = average deviation between stated confidence and actual accuracy. U-Recall (Unknown Detection Rate) = proportion of genuinely unknown questions correctly identified. REP (Response Epistemic Profile) = weighted score across epistemic markers. EpCE (Epistemic Calibration Error) = distance from GOLD reference profile. DLA (Dual-Layer Agreement) = consistency between linguistic and statistical analysis.</p>
<p>GOLD v4.5 contains 149 calibration files, 59 academic references, 92 epistemic markers across EM1-EM5 levels, and 7 epistemic domains (ED1-ED7: medical, legal, financial, technical, scientific, general, creative). ONTO-Bench benchmark: 268 samples across KNOWN (126), UNKNOWN (110), CONTRADICTION (32) with Tier-1 sources (Clay Mathematics Institute, NSF/ERC Grand Challenges) and Tier-2 sources (NIST, established textbooks).</p>
<p>Benchmark results: ONTO achieves 96% U-Recall compared to less than 10% for GPT-4, Claude 3, and Llama 3. Every evaluation through ROOT produces a 104-byte cryptographic proof (SHA-256 hash + Ed25519 signature + timestamp) — verifiable but unreproducible without original entropy signal.</p>
<p>Compliance grades A through F based on U-Recall and ECE thresholds. Grade A (EXEMPLARY): U-Recall ≥90%, ECE ≤0.05. Grade F (CRITICAL): U-Recall below 30%, ECE above 0.20. Maps to EU AI Act, NIST AI RMF 1.0, and ISO/IEC 42001.</p>
</article>
</div>

<!-- TOC scroll tracking -->
<script>
const sections = document.querySelectorAll('.meth-section');
const tocLinks = document.querySelectorAll('.toc a');
window.addEventListener('scroll', () => {
    let current = '';
    sections.forEach(s => {
        if (window.scrollY >= s.offsetTop - 120) current = s.id;
    });
    tocLinks.forEach(a => {
        a.classList.toggle('active', a.getAttribute('href') === '#' + current);
    });
});
</script>

</body>
</html>
