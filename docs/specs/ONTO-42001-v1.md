# ONTO 42001:2025

## AI Calibration Metrics Specification

**Version:** 1.0  
**Status:** Draft Standard  
**Date:** January 2025  
**Publisher:** ONTO Standards Committee  
**Document ID:** ONTO-SPEC-42001-v1

---

## Foreword

ONTO 42001 is part of the ONTO 42000 series of standards for Epistemic Risk Management in AI Systems.

This document was prepared by the ONTO Standards Committee (OSC), Working Group 1 — Metrics.

This first edition establishes the foundational metrics framework for measuring and reporting epistemic risk in artificial intelligence systems. It is designed to complement existing AI governance frameworks including ISO/IEC 42001, NIST AI RMF, and the EU AI Act.

The ONTO 42000 series comprises:

- **ONTO 42000** — Epistemic Risk Management Systems (ERMS) — Requirements
- **ONTO 42001** — AI Calibration Metrics Specification *(this document)*
- **ONTO 42002** — Epistemic Risk Governance Framework
- **ONTO 42003** — AI Liability Quantification Protocol
- **ONTO 42004** — Epistemic Benchmarking Methodology
- **ONTO 42005** — AI Epistemic Certification Requirements

---

## Introduction

Artificial intelligence systems increasingly make decisions that affect human welfare, safety, and rights. A critical but underaddressed dimension of AI risk is **epistemic risk** — the risk arising from the gap between what an AI system claims to know and what it actually knows.

Traditional AI evaluation metrics (accuracy, precision, recall, F1) measure performance on known test distributions. They do not measure:

1. Whether the system knows what it does not know
2. Whether confidence scores reflect actual probability of correctness
3. The downstream liability exposure from epistemic failures

This International Standard specifies metrics for quantifying epistemic risk, enabling organizations to:

- Measure AI calibration quality
- Detect unknown or out-of-distribution inputs
- Calculate composite risk scores
- Map epistemic performance to regulatory compliance
- Quantify liability exposure

---

## 1. Scope

This document specifies requirements for metrics used to measure epistemic risk in AI systems.

This document is applicable to:

a) AI systems that produce confidence scores, probabilities, or uncertainty estimates;

b) Organizations deploying AI systems in high-stakes domains including but not limited to healthcare, legal, financial, and critical infrastructure;

c) Auditors, regulators, and certification bodies assessing AI epistemic safety;

d) AI developers and researchers benchmarking calibration quality.

This document does not specify:

- Requirements for AI system architecture or implementation;
- Domain-specific safety thresholds (see ONTO 42002);
- Certification procedures (see ONTO 42005).

---

## 2. Normative References

The following documents are referred to in the text in such a way that some or all of their content constitutes requirements of this document.

- **ISO/IEC 22989:2022** — Artificial intelligence concepts and terminology
- **ISO/IEC 42001:2023** — Artificial intelligence — Management system
- **NIST AI 100-1** — AI Risk Management Framework
- **IEEE 7010-2020** — Wellbeing Metrics Standard for Ethical AI

---

## 3. Terms and Definitions

For the purposes of this document, the following terms and definitions apply.

### 3.1 epistemic risk

risk arising from the discrepancy between an AI system's claimed knowledge state and its actual knowledge state

Note 1: Epistemic risk is distinct from aleatoric risk (inherent randomness) and systematic bias.

Note 2: Epistemic risk manifests when AI systems are confident but wrong, or when they fail to recognize inputs outside their competence.

### 3.2 calibration

the degree to which an AI system's confidence scores correspond to actual frequencies of correctness

Note: A perfectly calibrated system that reports 70% confidence is correct exactly 70% of the time.

### 3.3 calibration error

quantitative measure of deviation between predicted confidence and observed accuracy

### 3.4 unknown

an input that lies outside the training distribution, knowledge boundary, or competence scope of an AI system

Note: Unknowns include out-of-distribution samples, novel concepts, ambiguous queries, and adversarial inputs.

### 3.5 unknown detection

the capability of an AI system to identify inputs it cannot reliably process

### 3.6 confidence score

a numerical value, typically in the range [0, 1], representing an AI system's self-assessed certainty in its output

### 3.7 epistemic passport

a standardized artifact documenting the epistemic risk profile of an AI system or deployment configuration

### 3.8 risk score

a composite metric aggregating multiple epistemic risk indicators into a single value

### 3.9 liability exposure

the quantified potential financial, legal, or operational impact resulting from epistemic failures

---

## 4. Epistemic Risk Model

### 4.1 General

The epistemic risk model defined in this standard comprises three layers:

a) **Metric Layer** — individual measurable quantities (4.2);

b) **Composite Layer** — aggregated risk scores (4.3);

c) **Impact Layer** — liability and governance mapping (4.4).

### 4.2 Metric Layer

The Metric Layer consists of mandatory and optional metrics as specified in Clauses 5 and 6.

Mandatory metrics:
- Expected Calibration Error (ECE) — see 5.2
- Uncertainty Recall (U-Recall) — see 6.2
- ONTO Risk Score (ORS) — see 7.2

Optional metrics:
- Maximum Calibration Error (MCE) — see 5.3
- Information Gap Ratio (IGR) — see Annex A.4

### 4.3 Composite Layer

The Composite Layer aggregates Metric Layer values into governance-actionable scores.

The primary composite metric is the ONTO Risk Score (ORS) as specified in Clause 7.

### 4.4 Impact Layer

The Impact Layer maps composite scores to:

a) Regulatory compliance status (see ONTO 42002);

b) Liability exposure quantification (see ONTO 42003);

c) Governance tier classification (see 8.2).

---

## 5. Calibration Metrics Requirements

### 5.1 General Requirements

Organizations claiming conformance to this standard **shall**:

a) Measure calibration error using at least one metric specified in this clause;

b) Report calibration metrics with methodology documentation;

c) Re-evaluate calibration metrics at intervals not exceeding those specified in 5.1.1.

#### 5.1.1 Measurement Frequency

Calibration metrics **shall** be measured:

a) Prior to initial deployment;

b) Following any model update or retraining;

c) At minimum intervals of:
   - 30 days for high-risk domains (healthcare, legal, financial);
   - 90 days for medium-risk domains;
   - 180 days for low-risk domains.

### 5.2 Expected Calibration Error (ECE)

#### 5.2.1 Definition

Expected Calibration Error (ECE) **shall** be computed as the weighted average of calibration gaps across confidence bins.

#### 5.2.2 Calculation

ECE **shall** be calculated according to the formula specified in Annex A.1.

#### 5.2.3 Binning Strategy

Organizations **shall** use one of the following binning strategies:

a) Equal-width bins with M = 10 bins (default);

b) Equal-mass bins with M = 15 bins;

c) Adaptive binning as specified in A.1.3.

The chosen strategy **shall** be documented and consistently applied.

#### 5.2.4 Thresholds

Table 1 specifies ECE threshold values for conformance levels.

**Table 1 — ECE Conformance Thresholds**

| Conformance Level | ECE Threshold | Classification |
|-------------------|---------------|----------------|
| Level 1 (Basic) | ECE ≤ 0.15 | Acceptable |
| Level 2 (Standard) | ECE ≤ 0.10 | Good |
| Level 3 (Institutional) | ECE ≤ 0.05 | Excellent |

### 5.3 Maximum Calibration Error (MCE)

#### 5.3.1 Definition

Maximum Calibration Error (MCE) captures the worst-case calibration gap across all bins.

#### 5.3.2 Calculation

MCE **shall** be calculated according to the formula specified in Annex A.2.

#### 5.3.3 Application

MCE **should** be reported alongside ECE for high-stakes applications where worst-case performance is critical.

---

## 6. Unknown Detection Requirements

### 6.1 General Requirements

Organizations claiming conformance to this standard **shall**:

a) Implement unknown detection capability;

b) Measure unknown detection performance using U-Recall as specified in 6.2;

c) Document the unknown taxonomy used for evaluation.

### 6.2 Uncertainty Recall (U-Recall)

#### 6.2.1 Definition

Uncertainty Recall (U-Recall) measures the proportion of unknown or out-of-distribution inputs correctly identified by the system's uncertainty mechanism.

#### 6.2.2 Calculation

U-Recall **shall** be calculated according to the formula specified in Annex A.3.

#### 6.2.3 Unknown Taxonomy

Organizations **shall** classify unknowns according to at least one of the following taxonomies:

a) **Distribution-based**: Out-of-distribution (OOD), near-OOD, far-OOD;

b) **Epistemic-based**: Knowledge gaps, temporal gaps, domain gaps;

c) **Operational-based**: Novel inputs, ambiguous inputs, adversarial inputs.

The taxonomy used **shall** be documented in the epistemic passport.

#### 6.2.4 Thresholds

Table 2 specifies U-Recall threshold values for conformance levels.

**Table 2 — U-Recall Conformance Thresholds**

| Conformance Level | U-Recall Threshold | Classification |
|-------------------|-------------------|----------------|
| Level 1 (Basic) | U-Recall ≥ 0.50 | Acceptable |
| Level 2 (Standard) | U-Recall ≥ 0.70 | Good |
| Level 3 (Institutional) | U-Recall ≥ 0.85 | Excellent |

### 6.3 Unknown Detection Mechanisms

#### 6.3.1 Acceptable Mechanisms

Unknown detection **may** be implemented using:

a) Confidence thresholding;

b) Entropy-based detection;

c) Ensemble disagreement;

d) Dedicated OOD detection models;

e) Embedding distance methods.

#### 6.3.2 Documentation

The mechanism used **shall** be documented including:

a) Detection method;

b) Threshold values;

c) Validation methodology.

---

## 7. Composite Risk Score Requirements

### 7.1 General Requirements

Organizations **shall** compute and report a composite risk score that integrates calibration and unknown detection metrics.

### 7.2 ONTO Risk Score (ORS)

#### 7.2.1 Definition

The ONTO Risk Score (ORS) is a composite metric providing a single governance-actionable value representing overall epistemic risk.

#### 7.2.2 Calculation

ORS **shall** be calculated according to the formula specified in Annex A.5.

The standard formula is:

```
ORS = 100 × [w₁ × ECE_norm + w₂ × (1 - U-Recall) + w₃ × Domain_Factor]
```

Where:
- w₁ = 0.35 (calibration weight)
- w₂ = 0.45 (unknown detection weight)
- w₃ = 0.20 (domain weight)

Domain_Factor values are specified in Table 3.

#### 7.2.3 Domain Factors

**Table 3 — Domain Risk Factors**

| Domain | Domain_Factor | Rationale |
|--------|---------------|-----------|
| Healthcare / Medical | 1.0 | Life-critical decisions |
| Legal / Judicial | 0.9 | Rights-affecting decisions |
| Financial / Insurance | 0.8 | Material impact decisions |
| Critical Infrastructure | 0.85 | Safety-critical systems |
| General Enterprise | 0.5 | Business impact |
| Consumer / Low-stakes | 0.3 | Limited impact |

#### 7.2.4 Score Interpretation

**Table 4 — ORS Interpretation**

| ORS Range | Risk Level | Recommended Action |
|-----------|------------|-------------------|
| 0–25 | Low | Standard monitoring |
| 26–50 | Moderate | Enhanced monitoring |
| 51–75 | High | Remediation required |
| 76–100 | Critical | Deployment suspension |

### 7.3 Alternative Composite Scores

Organizations **may** use alternative composite scoring methods provided:

a) The methodology is fully documented;

b) Mapping to ORS is provided;

c) Conformance thresholds are justified.

---

## 8. Conformance

### 8.1 Conformance Levels

This standard defines three conformance levels:

**Level 1 — Basic Conformance**

Requirements:
- ECE measured and documented
- U-Recall measured and documented
- ORS computed
- Thresholds from Tables 1, 2 met at Level 1

**Level 2 — Standard Conformance**

Requirements:
- All Level 1 requirements
- Thresholds from Tables 1, 2 met at Level 2
- Measurement frequency per 5.1.1
- Epistemic passport generated

**Level 3 — Institutional Conformance**

Requirements:
- All Level 2 requirements
- Thresholds from Tables 1, 2 met at Level 3
- Third-party verification
- Continuous monitoring implemented
- Liability quantification per ONTO 42003

### 8.2 Governance Tier Mapping

Conformance levels map to governance tiers as specified in ONTO 42002:

| Conformance Level | Governance Tier | Typical Deployment |
|-------------------|-----------------|-------------------|
| Level 1 | Tier 1 — Audit | Initial assessment |
| Level 2 | Tier 2 — Monitoring | Production deployment |
| Level 3 | Tier 3 — Certified | Regulated domains |

### 8.3 Conformance Statement

Organizations claiming conformance **shall** include:

a) Conformance level claimed;

b) Metrics values achieved;

c) Measurement date;

d) Methodology reference;

e) Scope of conformance.

Example conformance statement:

> "This AI system conforms to ONTO 42001:2025 Level 2. ECE: 0.08, U-Recall: 0.74, ORS: 38. Measured 2025-01-15 using methodology A.1.2. Scope: Production deployment, financial advisory domain."

---

## Annex A (Normative) — Mathematical Definitions

### A.1 Expected Calibration Error (ECE)

#### A.1.1 Formal Definition

Let a dataset D contain N samples. Partition predictions into M bins B₁, B₂, ..., Bₘ based on confidence scores.

For each bin Bₘ:
- acc(Bₘ) = accuracy of predictions in bin
- conf(Bₘ) = mean confidence of predictions in bin
- |Bₘ| = number of samples in bin

ECE is defined as:

```
ECE = Σₘ (|Bₘ| / N) × |acc(Bₘ) - conf(Bₘ)|
```

#### A.1.2 Equal-Width Binning

Bins are defined with boundaries:

```
Bₘ = { i : (m-1)/M ≤ confidence(i) < m/M }
```

For M = 10, bins are: [0, 0.1), [0.1, 0.2), ..., [0.9, 1.0].

#### A.1.3 Adaptive Binning

Adaptive binning adjusts bin widths to ensure minimum samples per bin:

```
min_samples_per_bin = max(50, N / (2 × M))
```

Bins with fewer samples **shall** be merged with adjacent bins.

### A.2 Maximum Calibration Error (MCE)

MCE is defined as:

```
MCE = maxₘ |acc(Bₘ) - conf(Bₘ)|
```

### A.3 Uncertainty Recall (U-Recall)

#### A.3.1 Formal Definition

Let:
- U = set of true unknown/OOD samples
- D(x) = 1 if system detects x as unknown, 0 otherwise

U-Recall is defined as:

```
U-Recall = |{x ∈ U : D(x) = 1}| / |U|
```

#### A.3.2 Detection Threshold

When using confidence thresholding:

```
D(x) = 1 if confidence(x) < τ
```

Where τ is the detection threshold. Default τ = 0.5.

### A.4 Information Gap Ratio (IGR)

#### A.4.1 Definition (Optional Metric)

IGR measures the ratio of information claimed versus information justified:

```
IGR = H(claimed) / H(justified)
```

Where H denotes information entropy.

#### A.4.2 Interpretation

- IGR = 1.0: Perfect epistemic efficiency
- IGR > 1.0: Overclaiming (epistemic risk)
- IGR < 1.0: Underclaiming (inefficiency)

### A.5 ONTO Risk Score (ORS)

#### A.5.1 Standard Formula

```
ORS = 100 × [0.35 × ECE_norm + 0.45 × (1 - U-Recall) + 0.20 × DF]
```

Where:
- ECE_norm = min(ECE / 0.3, 1.0)
- DF = Domain_Factor from Table 3

#### A.5.2 Bounds

ORS is bounded: 0 ≤ ORS ≤ 100.

#### A.5.3 Weight Customization

Organizations **may** customize weights provided:

a) w₁ + w₂ + w₃ = 1.0

b) No weight < 0.15

c) Justification documented

---

## Annex B (Informative) — Implementation Guidance

### B.1 Evaluation Dataset Requirements

#### B.1.1 Minimum Size

Evaluation datasets **should** contain:

- Minimum 1,000 samples for ECE calculation
- Minimum 500 unknown samples for U-Recall calculation

#### B.1.2 Distribution Requirements

Datasets **should** include:

- Representative in-distribution samples
- Known unknown categories
- Edge cases relevant to deployment domain

### B.2 Confidence Score Requirements

#### B.2.1 Acceptable Sources

Confidence scores **may** be derived from:

a) Softmax outputs (with temperature scaling);

b) Calibrated probability estimates;

c) Ensemble variance;

d) Dedicated confidence heads.

#### B.2.2 Calibration Methods

Pre-calibration using the following methods is acceptable:

- Temperature scaling
- Platt scaling
- Isotonic regression
- Histogram binning

### B.3 Reporting Format

#### B.3.1 Minimum Report Contents

Reports **should** include:

1. System identification
2. Evaluation date
3. Dataset description
4. All mandatory metrics
5. Conformance level claim
6. Methodology notes

#### B.3.2 Epistemic Passport Format

The epistemic passport **should** be provided in:

- JSON format for machine readability
- PDF format for human readability

Schema reference: ONTO-PASSPORT-SCHEMA-v1.json

### B.4 Common Implementation Errors

#### B.4.1 Errors to Avoid

- Using accuracy as proxy for calibration
- Evaluating only on in-distribution data
- Ignoring temporal distribution shift
- Using uncalibrated confidence scores

---

## Annex C (Informative) — Regulatory Mapping

### C.1 EU AI Act Alignment

ONTO 42001 metrics support EU AI Act Article 9 requirements:

| EU AI Act Requirement | ONTO 42001 Mapping |
|-----------------------|-------------------|
| Risk assessment | ORS computation |
| Accuracy metrics | ECE measurement |
| Robustness testing | U-Recall evaluation |
| Documentation | Epistemic passport |

### C.2 NIST AI RMF Alignment

| NIST AI RMF Function | ONTO 42001 Support |
|---------------------|-------------------|
| MEASURE | All metrics (Clause 5, 6, 7) |
| MANAGE | Conformance levels (Clause 8) |
| GOVERN | Governance tiers (8.2) |

### C.3 ISO/IEC 42001 Alignment

ONTO 42001 provides quantitative metrics supporting ISO/IEC 42001 management system requirements for AI risk assessment and monitoring.

---

## Annex D (Informative) — Liability Quantification Preview

### D.1 Scope

Full liability quantification methodology is specified in ONTO 42003. This annex provides a preview for planning purposes.

### D.2 Basic Formula

```
Annual_Liability_Exposure = Query_Volume × Failure_Rate × Incident_Cost × Domain_Multiplier
```

Where:
- Failure_Rate derives from (1 - U-Recall) and ECE
- Incident_Cost is domain-specific
- Domain_Multiplier from Table 3

### D.3 Reference Values

| Domain | Typical Incident Cost | Multiplier |
|--------|----------------------|------------|
| Medical Diagnosis | $2,400,000 | 3.0 |
| Legal Advisory | $890,000 | 2.0 |
| Financial Planning | $1,200,000 | 2.0 |
| Code Generation | $4,500,000 | 1.5 |

Full methodology: See ONTO 42003.

---

## Bibliography

[1] ISO/IEC 22989:2022, *Artificial intelligence — Artificial intelligence concepts and terminology*

[2] ISO/IEC 42001:2023, *Information technology — Artificial intelligence — Management system*

[3] NIST AI 100-1, *Artificial Intelligence Risk Management Framework*

[4] Guo, C., et al. (2017). "On Calibration of Modern Neural Networks." *ICML*.

[5] Ovadia, Y., et al. (2019). "Can You Trust Your Model's Uncertainty?" *NeurIPS*.

[6] Naeini, M.P., et al. (2015). "Obtaining Well Calibrated Probabilities Using Bayesian Binning." *AAAI*.

---

## Document History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2025-01 | Initial release |

---

## Contact

ONTO Standards Committee  
standards@ontostandard.org  
https://ontostandard.org/standards/42001

---

*© 2025 ONTO Standards Committee. This document may be freely distributed for non-commercial purposes with attribution.*
