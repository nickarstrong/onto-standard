# ONTO Sales Engine

## 90-Day Revenue Target: $20K MRR

---

## Week-by-Week Execution Plan

### Week 1: Pipeline Building
- [ ] Send 50 cold emails
- [ ] LinkedIn connection requests (20)
- [ ] Schedule 5+ discovery calls

### Week 2: Pilots
- [ ] Run 3-5 free pilot evaluations
- [ ] Generate executive reports
- [ ] Collect feedback

### Week 3: Conversion
- [ ] Follow up all pilots
- [ ] Send proposals
- [ ] Handle objections

### Week 4: Close
- [ ] Target: 2 paid customers
- [ ] $10K-$20K MRR secured
- [ ] Ask for referrals

---

## Target Customer Profiles

### Tier 1: AI Startups (Fastest to close)

**Profile:**
- Series A-C funded
- Building LLM-based product
- Shipping to enterprise customers
- Under pressure to prove safety

**Pain:**
- Enterprise customers asking "how do you prevent hallucination?"
- No good answer
- Need third-party validation

**Examples:**
- YC AI batch companies
- LLM wrapper startups
- AI copilot builders
- Vertical AI (legal, medical, finance)

### Tier 2: Enterprise AI Teams

**Profile:**
- Fortune 500 AI/ML team
- Deploying internal AI tools
- Compliance/legal asking questions

**Pain:**
- Legal wants "proof" AI is safe
- No industry standard to point to
- Need audit trail

### Tier 3: AI Safety Organizations

**Profile:**
- Non-profits, research orgs
- Evaluating AI systems
- Publishing safety reports

**Pain:**
- Need rigorous evaluation methodology
- Want reproducible benchmarks

---

## Cold Email Templates

### Template 1: The Problem Opener

```
Subject: Quick question about [COMPANY]'s AI hallucination risk

Hi [NAME],

I noticed [COMPANY] is building [PRODUCT] with LLMs.

Quick question: when enterprise customers ask about hallucination risk, what do you tell them?

We've found that GPT-4 and Claude detect genuinely unanswerable questions less than 10% of the time. The rest of the time, they confidently make things up.

We built ONTO-Bench to quantify this exact risk. Happy to run a free evaluation on your model if you want to know where you stand.

Takes 15 minutes. Report shows exactly where your AI confidently hallucinates.

Worth a quick look?

[NAME]
ONTO Project
```

### Template 2: The Compliance Angle

```
Subject: Before regulators ask about AI calibration

Hi [NAME],

EU AI Act. NYC bias audits. SEC AI disclosure rules.

Regulators are starting to ask: "Does your AI know what it doesn't know?"

Most AI teams can't answer this question with data.

We've built the first benchmark specifically measuring epistemic calibration—whether AI systems recognize the boundaries of their knowledge.

Spoiler: most models fail badly. GPT-4 scores 9% on unknown detection.

Happy to run a free pilot evaluation so you have the data before anyone asks.

15 minutes of your time. Full executive report.

Interested?

[NAME]
```

### Template 3: The Peer Pressure

```
Subject: How [COMPETITOR] is handling AI hallucination audits

Hi [NAME],

Just wrapped an epistemic evaluation for a company in [INDUSTRY].

They wanted data on hallucination risk before their Series B due diligence.

Result: their model was confidently answering questions that have no known answer 87% of the time. They're now implementing our recommendations before the round closes.

Given [COMPANY] is also selling to enterprises, thought you might want similar data.

Free pilot available this week.

[NAME]
```

### Template 4: The Research Hook

```
Subject: Our paper on epistemic calibration (relevant to [PRODUCT])

Hi [NAME],

We just published research showing that frontier LLMs fail dramatically at recognizing genuinely unanswerable questions.

Key finding: <10% recall on "unknown" detection across GPT-4, Claude, Llama.

Paper: [ARXIV_LINK]

Given [COMPANY] is building [PRODUCT], thought you might want to know where your model stands.

We can run a free evaluation—takes 15 min, generates a full risk report.

Interested?

[NAME]
```

### Template 5: The Direct Ask

```
Subject: Free AI hallucination audit for [COMPANY]

Hi [NAME],

I'll be direct: we help AI companies quantify hallucination risk before it becomes a liability.

Our benchmark (ONTO-Bench) measures whether AI knows what it doesn't know.

Most models fail badly. We can show you exactly where.

Free pilot evaluation available this week.

Yes or no?

[NAME]
```

---

## LinkedIn Messages

### Connection Request

```
Hi [NAME], I'm researching AI calibration/hallucination at [COMPANY]. 
Saw your work on [TOPIC] - would love to connect.
```

### Follow-up DM

```
Thanks for connecting!

Quick question: how does [COMPANY] currently measure hallucination risk?

We've built a benchmark showing most LLMs confidently answer questions that have no known answer. Happy to share the research or run a free evaluation if useful.
```

---

## Discovery Call Script

### Opening (2 min)

```
"Thanks for taking the time. Before I dive in—what made you take this call?"

[Let them talk. Note their specific pain.]

"Got it. Let me make sure I understand: [paraphrase their problem]"
```

### Problem Exploration (5 min)

```
"When your customers/legal team/board asks about AI reliability, what do you tell them?"

"Have you ever had an incident where the AI confidently gave a wrong answer?"

"What would happen if a hallucination caused a customer problem?"

"How do you currently measure whether your AI knows its limits?"
```

### Solution Overview (5 min)

```
"Let me show you what we found.

[Share screen: show benchmark results]

GPT-4 detects genuinely unanswerable questions 9% of the time.
Claude: similar.
Most models: worse.

The problem isn't that AI doesn't know things.
The problem is AI doesn't know what it doesn't know.

We built ONTO-Bench to measure exactly this.

[Show sample report]

This is what an enterprise customer gets: risk score, calibration analysis, specific recommendations."
```

### Pilot Offer (3 min)

```
"Here's what I'd suggest:

Let us run a free evaluation on your model.
Takes 15 minutes of your time.
You get the full executive report.

If the results are useful, we can talk about ongoing monitoring.
If not, you've lost nothing and gained data.

Sound fair?"
```

### Closing

```
"Great. I'll send you the test set and instructions today.
Can you have predictions back by [DATE]?
I'll have your report within 24 hours of submission."
```

---

## Objection Handling

### "We don't have budget"

```
"Totally understand. That's why we offer a free pilot—no commitment.

Most teams find the results valuable enough to bring to leadership. 
If not, you've lost nothing.

Want to try the free evaluation first?"
```

### "We built our own eval"

```
"That's great that you're measuring this. What metrics are you tracking?

[Listen]

The unique thing about ONTO is we specifically measure unknown detection—
whether the model recognizes genuinely unanswerable questions.

Most internal evals miss this because they focus on accuracy on known questions.

Worth comparing? Free pilot takes 15 min."
```

### "Our model is fine"

```
"That's possible. But here's what we've found:

Every model we've tested—GPT-4, Claude, Llama—fails on unknown detection.
Not because they're bad at facts, but because they don't know their limits.

The free pilot will show you where you stand.
If you're the first model to pass, that's a huge marketing win.

Want to find out?"
```

### "We'll do it later"

```
"I hear you. Quick question:

When's your next enterprise deal closing?
When's your next board meeting?
When's your next compliance review?

Having this data before those conversations is usually valuable.

The pilot takes 15 minutes. Report in 24 hours.
Can we knock it out this week?"
```

### "What's the catch?"

```
"No catch. Here's our model:

Free pilot shows you the problem.
If it's bad (usually is), you want monitoring.
Paid plans give you ongoing evaluation + compliance reports.

We make money when you see value.
If you don't, we don't.

Fair?"
```

---

## Pilot → Paid Conversion Flow

### Day 0: Pilot Delivered

```
Subject: Your ONTO Evaluation Report

Hi [NAME],

Attached is your epistemic evaluation report for [MODEL].

Key findings:
- Risk Level: [CRITICAL/HIGH/MEDIUM]
- Unknown Detection: [X%]
- Top recommendation: [SPECIFIC ACTION]

Happy to walk through the details on a quick call.

Available [DATE/TIME]?

[NAME]
```

### Day 3: Check-in

```
Subject: Thoughts on the ONTO report?

Hi [NAME],

Wanted to check in—did you get a chance to review the evaluation?

Any questions on the findings or recommendations?

Happy to do a 15-min walkthrough if helpful.

[NAME]
```

### Day 7: Value Recap

```
Subject: Next steps on epistemic monitoring

Hi [NAME],

Following up on your ONTO evaluation.

Based on your results ([RISK LEVEL] risk, [X%] unknown detection),
here's what I'd recommend:

1. Implement [SPECIFIC RECOMMENDATION]
2. Re-evaluate in 30 days to measure improvement
3. Generate compliance-ready reports for stakeholders

Our Pro plan ($10K/mo) includes:
- 100 evaluations/month
- Priority processing
- Slack support
- Compliance documentation

Want to discuss which plan makes sense for [COMPANY]?

[NAME]
```

### Day 14: Close or Qualify Out

```
Subject: Quick question

Hi [NAME],

Haven't heard back—totally fine if timing isn't right.

Quick question: is AI evaluation still a priority for [COMPANY] this quarter?

If yes: happy to set up a quick call to discuss next steps.
If no: no problem, I'll check back next quarter.

Either way, let me know so I can update my notes.

[NAME]
```

---

## Pricing Conversation

### When they ask "How much?"

```
"Depends on your needs. Quick questions:

1. How many models do you need to evaluate?
2. How often do you want reports?
3. Do you need compliance documentation?

[Based on answers]

Sounds like [STARTER/PRO/ENTERPRISE] would fit.
That's [$X]/month.

Includes [LIST FEATURES].

Want me to send a proposal?"
```

### Anchoring

```
"Full epistemic audit with consulting is $50K+.

For ongoing monitoring, most teams are on Pro at $10K/month.

But let's start with a pilot and see if the data is valuable first."
```

---

## Success Metrics

### Week 1
- Emails sent: 50
- Response rate: 10-15%
- Calls scheduled: 5+

### Week 2
- Discovery calls: 5
- Pilots started: 3-5
- Reports delivered: 3-5

### Week 3
- Proposals sent: 3
- Follow-ups completed: All

### Week 4
- Deals closed: 2
- MRR: $10K-$20K
- Referrals asked: 2

---

## CRM Tracking (Notion/Spreadsheet)

| Company | Contact | Stage | Next Action | Notes |
|---------|---------|-------|-------------|-------|
| Acme AI | john@acme | Pilot Delivered | Follow up 1/30 | High interest |
| Beta Corp | jane@beta | Discovery Call | Send pilot 1/28 | Legal pain |
| ... | ... | ... | ... | ... |

**Stages:**
1. Lead (identified)
2. Contacted (email sent)
3. Responded (got reply)
4. Discovery (call scheduled/completed)
5. Pilot (evaluation running)
6. Proposal (sent pricing)
7. Negotiation (discussing terms)
8. Closed Won / Lost

---

## Referral Ask

After closing or after positive pilot:

```
"Glad this was valuable.

Quick ask: do you know 2-3 other AI teams who might have the same challenges?

Happy to give them a free pilot too.

Anyone come to mind?"
```

---

*ONTO Sales Engine v1.0*
*Target: $20K MRR in 90 days*
