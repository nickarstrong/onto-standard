# ONTO Enterprise Sales Deck

## Slide-by-Slide Content

---

### SLIDE 1: Title

```
ONTO

AI Hallucination Liability Audit

Know What Your AI Doesn't Know
Before Regulators Ask
```

---

### SLIDE 2: The $10M Question

```
What happens when your AI confidently 
gives a wrong answer to a customer?

• Legal liability
• Regulatory fines
• Brand damage
• Lost enterprise deals

One AI incident = $10M+ exposure
```

---

### SLIDE 3: The Hidden Risk

```
Your AI doesn't know what it doesn't know.

GPT-4 detects genuinely unanswerable questions: 9%
Claude: 8%
Llama: 2%

The other 90%+ of the time?
Confident hallucination.
```

---

### SLIDE 4: Regulatory Reality

```
EU AI Act (2024)
• Fines up to 6% of global revenue
• High-risk AI requires risk assessments
• Documentation of AI limitations mandatory

US Developments
• FTC AI enforcement actions increasing
• SEC AI disclosure rules
• State-level AI liability laws

The question isn't IF regulators will ask.
It's WHEN.
```

---

### SLIDE 5: What We Measure

```
ONTO Epistemic Risk Score

Not "Is the AI accurate?"
But "Does the AI know its limits?"

We measure:
• Hallucination liability exposure
• Confidence calibration
• Knowledge boundary recognition

Result: Single compliance score (0-100)
```

---

### SLIDE 6: Sample Report

```
┌─────────────────────────────────────┐
│  ONTO RISK ASSESSMENT              │
├─────────────────────────────────────┤
│                                     │
│  Compliance Score:  25/100 (FAIL)  │
│  Risk Level:        CRITICAL        │
│  Grade:             F               │
│                                     │
│  Hallucination Rate:    91%         │
│  Calibration Error:     0.34        │
│  Regulatory Exposure:   HIGH        │
│                                     │
│  ⚠️ NOT RECOMMENDED for regulated   │
│     deployment without remediation  │
│                                     │
└─────────────────────────────────────┘
```

---

### SLIDE 7: ROI Calculator

```
WITHOUT ONTO:
• 1 AI incident lawsuit: $10M+
• Regulatory fine (EU AI Act): 6% revenue
• Lost enterprise deal: $500K-$5M
• Brand damage: Incalculable

WITH ONTO:
• Epistemic Risk Audit: $50K
• Ongoing monitoring: $10K/mo
• Documented compliance: Priceless

ROI: Prevent one incident = 400x return
```

---

### SLIDE 8: How It Works

```
1. SUBMIT
   Run your model on ONTO-Bench test set
   (55 carefully curated questions)
   Time: 15 minutes

2. ANALYZE
   We compute hallucination liability metrics
   Unknown detection, calibration, confidence
   Time: 24 hours

3. REPORT
   Executive risk report
   Compliance score
   Actionable recommendations
```

---

### SLIDE 9: Who We Help

```
AI Startups
"Enterprise customers ask about hallucination risk.
 Now we have data."

Enterprise AI Teams
"Legal wanted proof our AI is safe.
 ONTO gave us documentation."

Regulated Industries
"Healthcare AI needs FDA-ready evidence.
 ONTO provides the metrics."
```

---

### SLIDE 10: Pricing

```
┌────────────────────────────────────────────┐
│  PILOT        FREE                         │
│  • 1 evaluation                            │
│  • Full report                             │
│  • 14 days                                 │
├────────────────────────────────────────────┤
│  AUDIT        $50K one-time               │
│  • Comprehensive evaluation                │
│  • Executive briefing                      │
│  • Remediation roadmap                     │
├────────────────────────────────────────────┤
│  MONITORING   $10K-$50K/month             │
│  • Continuous evaluation                   │
│  • Compliance documentation                │
│  • Priority support                        │
├────────────────────────────────────────────┤
│  ENTERPRISE   Custom                       │
│  • On-premise deployment                   │
│  • Custom benchmarks                       │
│  • Dedicated support                       │
└────────────────────────────────────────────┘
```

---

### SLIDE 11: Next Steps

```
1. Free Pilot Evaluation
   → See your AI's risk score in 24 hours

2. Executive Briefing
   → We walk through findings with your team

3. Decide
   → Monitoring, audit, or integration

No commitment required for pilot.
```

---

### SLIDE 12: Contact

```
ONTO
AI Hallucination Liability Audit

Website: onto-bench.org/enterprise
Email: enterprise@onto-bench.org

"Know what your AI doesn't know."
```

---

## Key Talking Points

### For CTO/VP Engineering
- "We measure whether your model knows its limits"
- "This is the metric enterprise customers will ask about"
- "15 minutes to run, 24 hours to report"

### For Legal/Compliance
- "EU AI Act requires documented risk assessment"
- "We provide audit-ready documentation"
- "Single compliance score for board reporting"

### For CEO/Founder
- "One AI incident = $10M+ liability"
- "Audit costs $50K. Insurance for your AI."
- "Differentiate from competitors with verified safety"

---

## Objection Responses

### "We test our models already"

"You test accuracy. We test liability exposure. 

Traditional evals ask: 'Did the AI get it right?'
ONTO asks: 'Does the AI know when it CAN'T get it right?'

That's the difference between a missed answer and a lawsuit."

---

### "We don't have budget"

"What's the cost of one AI incident?

Lawsuit: $10M+
Regulatory fine: 6% of revenue
Lost enterprise deal: $500K-$5M

ONTO audit: $50K

That's not a cost. It's insurance."

---

### "Our model is fine"

"Every model we've tested—GPT-4, Claude, Llama—fails on unknown detection.

Not because they're bad at facts.
Because they don't know their limits.

The pilot is free. If you pass, that's a marketing win.
If you don't, you'll know before your customers do."

---

### "We'll do it later"

"When's your next enterprise deal closing?
When's your next board meeting?
When's EU AI Act enforcement starting?

Having this data before those conversations is the difference between 'we think we're safe' and 'here's our compliance score.'

Pilot takes 15 minutes. Report in 24 hours."

---

### "What's the catch?"

"No catch. Here's our model:

Free pilot shows you the problem.
If it's bad (usually is), you want monitoring.
We make money when you see value.

If your AI is actually well-calibrated, you've lost nothing and gained proof."

---

## Discovery Call Questions

### Opening
- "What made you take this call?"
- "What's your biggest concern about AI reliability right now?"

### Pain Discovery
- "When customers/legal/board asks about hallucination, what do you tell them?"
- "Have you ever had an incident where AI gave a confidently wrong answer?"
- "How do you currently measure AI reliability?"

### Qualification
- "Are you deploying to enterprise customers?"
- "Are you in a regulated industry?"
- "Who else needs to be involved in this decision?"

### Close
- "Want us to run a free pilot so you have data for those conversations?"
- "Can you get predictions back to us by [DATE]?"

---

*ONTO Enterprise Sales Deck v1.0*
