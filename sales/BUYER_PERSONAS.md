# ONTO Buyer Personas

## Who Signs the Check?

---

## PRIMARY BUYER: VP/Head of AI/ML

### Profile
- **Title:** VP AI, Head of ML, Director of AI Engineering
- **Reports to:** CTO or CPO
- **Budget:** Platform/Infrastructure or R&D
- **Team size:** 5-50 engineers

### Responsibilities
- AI model development and deployment
- Model performance and reliability
- Team productivity and velocity
- Incident response for AI issues

### Pain Points
- "Enterprise customers ask about AI safety and I don't have good answers"
- "We're shipping faster than we can validate"
- "Legal/compliance is starting to ask questions I can't answer"
- "I don't have metrics for what I can't measure"

### Triggers to Buy
- Lost enterprise deal due to AI safety concerns
- Board/CEO asking about AI risk
- Competitor got a safety certification
- EU AI Act deadline approaching

### Objections
- "We test internally already"
- "Our model is accurate enough"
- "This is a nice-to-have"

### How to Sell
- Lead with **competitive differentiation**: "Your competitors will have this certification"
- Show **enterprise deal enablement**: "Here's what you can show customers"
- Offer **free pilot**: "15 minutes, no risk, full report"

### Email Opening
```
Subject: AI safety question from enterprise customers

Hi [NAME],

When enterprise customers ask about AI hallucination risk,
what data do you show them?

Most AI teams can't answer with metrics.
That's becoming a deal-breaker.

We quantify exactly this. Free pilot available.
```

---

## SECONDARY BUYER: Chief Risk Officer / VP Risk

### Profile
- **Title:** CRO, VP Risk Management, Head of Risk
- **Reports to:** CEO or CFO
- **Budget:** Risk Management / Insurance
- **Team size:** 3-20

### Responsibilities
- Enterprise risk identification and mitigation
- Regulatory compliance
- Insurance and liability management
- Board risk reporting

### Pain Points
- "AI is a black box to me"
- "I don't know how to quantify AI risk"
- "Regulators are asking about AI and I don't have answers"
- "This risk isn't on our register but it should be"

### Triggers to Buy
- Board audit committee questions about AI
- Insurance carrier asking about AI liability
- Regulatory inquiry or guidance
- Peer company AI incident

### Objections
- "This is IT's problem"
- "We don't have AI-specific budget"
- "What's the regulatory requirement?"

### How to Sell
- Lead with **regulatory exposure**: "EU AI Act fines are 6% of revenue"
- Show **quantified risk**: "Your expected annual loss is $1.2M"
- Provide **board-ready reporting**: "Single score for risk committee"

### Email Opening
```
Subject: AI liability on your risk register?

Hi [NAME],

Quick question: does your enterprise risk register 
include AI hallucination liability?

Most don't. It should.

EU AI Act fines: 6% of global revenue.
Average AI lawsuit: $5M+.

We quantify this risk. 10-minute call?
```

---

## TERTIARY BUYER: General Counsel / VP Legal

### Profile
- **Title:** GC, VP Legal, Chief Legal Officer, AI Counsel
- **Reports to:** CEO
- **Budget:** Legal / Compliance
- **Team size:** 3-15

### Responsibilities
- Legal risk management
- Regulatory compliance
- Contract review (including AI clauses)
- Litigation prevention

### Pain Points
- "I can't evaluate AI claims made by engineering"
- "We're signing contracts with AI warranty clauses"
- "What's our liability exposure if AI is wrong?"
- "How do I defend AI decisions in court?"

### Triggers to Buy
- Customer contract requiring AI safety documentation
- Regulatory guidance on AI (EU AI Act, FTC)
- Peer company AI lawsuit
- Board asking about AI liability

### Objections
- "Engineering says we're fine"
- "We're not in regulated industry"
- "What's the legal precedent?"

### How to Sell
- Lead with **case law**: "Air Canada, lawyer ChatGPT cases..."
- Show **defensibility**: "Third-party validated metrics"
- Provide **documentation**: "Audit trail for litigation"

### Email Opening
```
Subject: AI liability documentation

Hi [NAME],

When AI confidently gives wrong answers, who's liable?

Recent cases (Air Canada chatbot, lawyer ChatGPT) 
show courts are holding companies accountable.

We provide the documentation that proves you tried 
to prevent it. Could save a lawsuit.

15-minute call?
```

---

## INFLUENCER: AI Safety/Responsible AI Lead

### Profile
- **Title:** Head of Responsible AI, AI Ethics Lead, AI Safety
- **Reports to:** VP AI or Chief Ethics Officer
- **Budget:** Usually none (influences, doesn't buy)
- **Team size:** 1-5

### Responsibilities
- AI ethics policy
- Safety evaluations
- Bias and fairness testing
- Stakeholder communication

### Pain Points
- "I don't have tools to do my job"
- "Engineering doesn't take safety seriously"
- "I need metrics to make my case internally"
- "Leadership doesn't understand the risk"

### Triggers to Engage
- Looking for evaluation frameworks
- Preparing internal AI safety report
- Benchmarking against industry
- Building case for AI safety investment

### How to Engage
- **Research angle**: Share paper, methodology
- **Benchmarking**: "Compare your model to industry"
- **Internal champion**: "Data to convince leadership"

### Email Opening
```
Subject: ONTO-Bench research on epistemic calibration

Hi [NAME],

Saw you're working on AI safety at [COMPANY].

We published research showing frontier LLMs detect 
genuinely unanswerable questions <10% of the time.

Might be relevant to your internal evaluations.
Happy to share methodology or run a comparison.

Paper: [LINK]
```

---

## BUYER JOURNEY MAP

```
Stage 1: AWARENESS
  Influencer (AI Safety Lead) discovers ONTO
  ↓ shares internally

Stage 2: INTEREST
  Technical buyer (VP AI) sees relevance
  ↓ requests pilot

Stage 3: EVALUATION
  Pilot completed, report generated
  ↓ shares with stakeholders

Stage 4: DECISION
  Economic buyer (CRO or CFO) reviews ROI
  ↓ approves budget

Stage 5: PURCHASE
  Legal review, procurement
  ↓ contract signed

Stage 6: EXPANSION
  Additional models, certification
```

---

## MULTI-THREADING STRATEGY

### For Large Deals ($50K+), Engage:

1. **VP AI** (Technical validation)
   - Pilot, methodology review
   - "Will this work for us?"

2. **CRO** (Risk validation)
   - ROI calculator, risk quantification
   - "Is this a real risk?"

3. **Legal** (Compliance validation)
   - Regulatory mapping, documentation
   - "Does this protect us?"

4. **CFO** (Budget approval)
   - CFO pitch deck, ROI summary
   - "Is this worth the money?"

### Email Sequence for Multi-Threading

**Week 1:** VP AI (technical pitch)
**Week 2:** CRO (risk pitch) + CC VP AI
**Week 3:** Legal (compliance pitch) + CC CRO
**Week 4:** CFO (ROI pitch) + CC all

---

## QUALIFICATION CRITERIA (BANT)

### Budget
- [ ] Does risk/compliance budget exist?
- [ ] Is AI safety a budget line item?
- [ ] Can they spend $50K-$250K?

### Authority
- [ ] Can this person approve spend?
- [ ] Who else needs to sign off?
- [ ] Is there a procurement process?

### Need
- [ ] Have they lost deals to AI safety concerns?
- [ ] Are regulators asking questions?
- [ ] Do enterprise customers require documentation?

### Timeline
- [ ] Is there a forcing event (regulation, audit, deal)?
- [ ] Are they evaluating now or "researching"?
- [ ] When is their budget cycle?

### Disqualification Signals
- "We're a very early startup" (no budget)
- "We don't serve enterprise" (no pain)
- "AI is experimental for us" (no urgency)
- "I'm just researching" (no authority)

---

## PERSONA-BASED PITCH MATRIX

| Buyer | Lead With | Proof Points | Close With |
|-------|-----------|--------------|------------|
| VP AI | Competitive advantage | Industry benchmarks | Free pilot |
| CRO | Quantified risk | ROI calculator | Risk report |
| Legal | Case law | Compliance docs | Audit trail |
| CFO | ROI | Financial model | Payback period |
| AI Safety | Methodology | Research paper | Benchmarking |

---

*ONTO Buyer Personas v1.0*
*Know who you're selling to*
